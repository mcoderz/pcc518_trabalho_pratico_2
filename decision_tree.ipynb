{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = '/opt/jdk'  #Mostra aonde est√° o JDK\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF,IDF\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/3.1.2/\n",
    "\n",
    "https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.ml.classification.DecisionTreeClassifier.html#pyspark.ml.classification.DecisionTreeClassifier\n",
    "\n",
    "\n",
    "https://spark.apache.org/docs/3.1.2/api/java/org/apache/spark/ml/classification/DecisionTreeClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.ml.evaluation.MulticlassClassificationEvaluator.html#multiclassclassificationevaluator\n",
    "\n",
    "\n",
    "https://spark.apache.org/docs/3.1.2/api/java/org/apache/spark/ml/evaluation/MulticlassClassificationEvaluator.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#spark = SparkSession.builder \\\n",
    "#        .appName('app_name') \\\n",
    "#        .master('local[*]') \\\n",
    "#        .config('spark.sql.execution.arrow.pyspark.enabled', True) \\\n",
    "#        .config('spark.sql.session.timeZone', 'UTC') \\\n",
    "#        .config('spark.driver.memory','12G') \\\n",
    "#        .config('spark.ui.showConsoleProgress', True) \\\n",
    "#        .config('spark.sql.repl.eagerEval.enabled', True) \\\n",
    "#        .getOrCreate()\n",
    "\n",
    "#sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .appName('my-cool-app') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_df_test = 'data_test.csv'\n",
    "caminho_df_training = 'data_training.csv'\n",
    "#caminho_df_test = 'menordata_test.csv'\n",
    "#caminho_df_training = 'menordata_training.csv'\n",
    "\n",
    "df_test = spark.read.csv(caminho_df_test, header=True, inferSchema=True)\n",
    "df_training = spark.read.csv(caminho_df_training, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"topico\", outputCol = \"label\", handleInvalid='keep')\n",
    "tokenization = Tokenizer(inputCol=\"texto\", outputCol=\"palavras\")\n",
    "remover_stopword = StopWordsRemover(inputCol=\"palavras\", outputCol=\"palavras_filtradas\")\n",
    "hashingTF = HashingTF(inputCol=\"palavras_filtradas\", outputCol=\"tf_features\")\n",
    "idf = IDF(inputCol=\"tf_features\", outputCol=\"tf_idf_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol='tf_idf_features', labelCol='label')\n",
    "pipelineDT = Pipeline(stages=[label_stringIdx, tokenization, remover_stopword, hashingTF, idf, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtparamGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [2, 3, 5])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcv = CrossValidator(estimator = pipelineDT,\n",
    "                      estimatorParamMaps = dtparamGrid,\n",
    "                      evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\"),\n",
    "                      numFolds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcvModel = dtcv.fit(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_nbcvModel = dtcvModel.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictionAndLabels = df_test_nbcvModel.select(['prediction', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_predictionAndLabels.rdd.map(lambda x: x.label).distinct().collect() # transforma o df para rdd e para poder extrair criar uma lista de labels distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_fMeasureByLabel = []\n",
    "qtdClasses = 0\n",
    "metric_list=[]\n",
    "\n",
    "for label in sorted(labels):\n",
    "    precisionByLabel = evaluator.evaluate(df_predictionAndLabels, {evaluator.metricName: \"precisionByLabel\", evaluator.metricLabel: label})\n",
    "    recallByLabel = evaluator.evaluate(df_predictionAndLabels, {evaluator.metricName: \"recallByLabel\", evaluator.metricLabel: label})\n",
    "    fMeasureByLabel = evaluator.evaluate(df_predictionAndLabels, {evaluator.metricName: \"fMeasureByLabel\", evaluator.metricLabel: label})\n",
    "    \n",
    "    metric_tuple_one = (label, precisionByLabel, recallByLabel,fMeasureByLabel, None , None)\n",
    "    \n",
    "    metric_list.append(metric_tuple_one)\n",
    "    \n",
    "    vec_fMeasureByLabel.append(fMeasureByLabel)\n",
    "    qtdClasses +=1 \n",
    "\n",
    "accuracy = evaluator.evaluate(df_predictionAndLabels, {evaluator.metricName: \"accuracy\"})\n",
    "macroF1 = (sum(vec_fMeasureByLabel))/qtdClasses\n",
    "\n",
    "metric_tuple_two = (None,None,None,None, accuracy, macroF1)\n",
    "\n",
    "metric_list.append(metric_tuple_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_metrics = pd.DataFrame(metric_list)\n",
    "dt_metrics.columns=(['class', 'precision', 'recall', 'F1', 'accuracy', 'macroF1'])\n",
    "dt_metrics.to_csv('metrics_decision_tree.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f907cd9e5acd71679984a0a8a82a3702c387a74b9b3fdd18bd9eaf613e7331a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ri': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
